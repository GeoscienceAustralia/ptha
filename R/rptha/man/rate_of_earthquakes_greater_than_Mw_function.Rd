% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/rupture_probabilities.R
\name{rate_of_earthquakes_greater_than_Mw_function}
\alias{rate_of_earthquakes_greater_than_Mw_function}
\title{Get a function to compute the rate of earthquakes with magnitude > Mw}
\usage{
rate_of_earthquakes_greater_than_Mw_function(slip_rate, slip_rate_prob, b,
  b_prob, Mw_min, Mw_min_prob, Mw_max, Mw_max_prob, sourcezone_total_area,
  event_table, event_conditional_probabilities,
  computational_increment = 0.01,
  Mw_frequency_distribution = "truncated_gutenberg_richter",
  Mw_frequency_distribution_prob = 1,
  update_logic_tree_weights_with_data = FALSE, Mw_count_duration = c(NA, NA,
  NA), Mw_obs_data = list(Mw = NULL, t = NULL), Mw_2_M0 = function(x)
  M0_2_Mw(x, inverse = TRUE), account_for_moment_below_mwmin = FALSE,
  mw_max_posterior_equals_mw_max_prior = FALSE,
  mw_observation_error_cdf = NULL)
}
\arguments{
\item{slip_rate}{numeric vector with 1 or more long-term seismogenic slip
rates for the source-zone (m/year). This gives the long-term average slip on
the fault due to seismic events (creep is ignored, so these rates must
account for the rate of coupling)}

\item{slip_rate_prob}{numeric vector with weights for the slip_rate
parameters}

\item{b}{numeric vector with 1 or more 'b' parameters}

\item{b_prob}{numeric vector with weights for the b parameters}

\item{Mw_min}{numeric vector with 1 or more 'Mw_min' parameters}

\item{Mw_min_prob}{numeric vector with weights for the Mw_min parameters}

\item{Mw_max}{numeric vector with 1 or more 'Mw_max' parameters}

\item{Mw_max_prob}{numeric vector with weights for the Mw_max parameters}

\item{sourcezone_total_area}{The total area of the sourcezone (km^2)}

\item{event_table}{A data.frame containing information on all events in the
source-zone. Output of \code{get_all_earthquake_events}. This is needed to
evaluate the RHS of the seismic moment balance equation.}

\item{event_conditional_probabilities}{A vector of conditional probabilities
for all events in the source-zone (conditional on the fact than an event with
their magnitude did occur). Output of
\code{get_event_probabilities_conditional_on_Mw}. This is needed to evaluate
the RHS of the seismic moment balance equation.}

\item{computational_increment}{For each parameter combination in the logic
tree, the rate function is computed at points in a sequence from min(Mw_min)
to max(Mw_max), with spacing computational_increment (adjusted if required so
that the extremes are included). The function value is then evaluated via
lookup.}

\item{Mw_frequency_distribution}{character vector giving the variant on the
Gutenberg Richter model used (if more than 1 they are passed to the logic
tree).  Either 'truncated_gutenberg_richter' or
'characteristic_gutenberg_richter'.}

\item{Mw_frequency_distribution_prob}{numeric vector. Logic tree weights for
each Mw_frequency_distribution type}

\item{update_logic_tree_weights_with_data}{logical. If TRUE, then a value for
Mw_count_duration must be provided. The weights for each parameter
combination in the tree are then updated with Bayes-theorem, based on the
probability that they would produce Mw_count_duration[2] events which exceed
Mw_count_duration[1] within time duration Mw_count_duration[3]. This assumes
earthquake timings follow a Poisson-process.}

\item{Mw_count_duration}{numeric vector of length 3 providing some data. The
first entry is an Mw value, the second is the number of events exceeding Mw
at the site, and the third is the duration of observation (in years).  If
\code{update_logic_tree_weights_with_data=TRUE} but Mw_obs_data$t is not
provided, this is used to re-weight parameter combinations in the logic
tree, with more weight given to those which predict similar event
frequencies as the data.}

\item{Mw_obs_data}{optional list containing earthquake event data
(corresponding to Mw_count_duration) which is used to re-weight logic tree
branches. This allows for more detailed use of data, as compared with the
simple Mw_count_duration approach. The use of data is only attempted if
"update_logic_tree_weights_with_data=TRUE". \cr
Mw_obs_data may contain: (1) a member Mw_obs_data$Mw having moment-magnitude
data for the historic events, and/or (2) a member Mw_obs_data$t, giving the
time in years of the event **since the observational start time**. \cr 
Either of the 'Mw' or 't' vectors vectors may also be NULL, in which case
they will be ignored (and in the 't' case, we will just use Mw_count_duration
if provided). \cr
If Mw_obs_data$Mw is not null, we use the likelihood of the 'Mw' data under
each logic tree branch to re-weight the logic tree branches [in addition to
use of temporal data]. The data must have "min(Mw_obs_data$Mw) >=
Mw_count_duration[1]" and "length(Mw_obs_data$Mw) = Mw_count_duration[2]".
The likelihood is evaluated by numerically differentiating each modelled GR
curve (normalised to a density for values above Mw_count_duration[1]). The
numerical differentiation uses a central difference which should be
acceptably accurate although not perfectly exact. The central difference has numerical
increment equal to 1.0e-04 if mw_observation_error_cdf=NULL, and otherwise the latter 
is equal to computational_increment. \cr
If Mw_obs_data$t is not null (NOT RECOMMENDED DUE TO BIAS, see below), then
we assume event occurrence times are a realisation of a Poisson process
(treating the time before the first event and the time after the last event
as censored observations). BEWARE THAT CENSORED MAXIMUM LIKELIHOOD IS BIASED
DOWNWARD FOR THIS PROBLEM, SEE
https://stats.stackexchange.com/questions/133347/ml-estimate-of-exponential-distribution-with-censored-data
In practice it is better to use the 'Poisson counts' approach above, but we
include the censored approach because it will generalise to non-Poisson interevent
times more easily (not currently implemented). With the censored approach,
note the time between the last event and the end of observations is inferred
as (Mw_count_duration[3] - t[length(t)]), while the time before the first
event is just t[1], so we must have Mw_obs_data$t[1] >= 0 and
max(Mw_obs_data$t) <= Mw_count_duration[3]. \cr
It is worth noting a situation when the use of detailed temporal data is identical to the
simpler approach of providing only Mw_count_duration. Consider a case where
Mw_obs_data$t=NULL and Mw_obs_data$Mw=NULL, and Mw_count_duration = c(7.5, 3,
50). This will give the same answer as having Mw_obs_data$Mw=NULL,
Mw_obs_data$t=c(0, 10, 30, 50), Mw_count_duration = c(7.5, 4, 50). Notice how
A) the observed event times begin at 0 and end at the last observed event
time; B) We need one more event than when we just provided the
Mw_count_duration data! This is because the 'censored' information provides
no information in this case [we already know 'time-between-events' >=0], and
we end up with 3 useful 'time-between-event' values.}

\item{Mw_2_M0}{function which takes an earthquake magnitude and returns the
corresponding seismic moment M0}

\item{account_for_moment_below_mwmin}{logical. If FALSE assume all
seismically coupled slip occurs due to earthquakes with Mw > Mwmin. If TRUE,
estimate the fraction of seismically coupled slip that occurs due to
earthquakes with Mw > Mwmin, and use that when computing the rates.}

\item{mw_max_posterior_equals_mw_max_prior}{logical. If TRUE, then do the Bayesian
update on a 'per-mw-max' level, i.e. the posterior of mw_max will be the
same as the prior of mw_max.}

\item{mw_observation_error_cdf}{If not NULL, a function F(x, Mw_true) giving the
probability that {(Mw_obs - Mw_true) <= x} if Mw-true takes a known value. Here
the observed Mw_obs has some error. In other words, if Mw_true is fixed,
then F is a cumulative distribution function for the error in Mw_obs. While this
CDF does not have to be a function of Mw_true, it is useful to allow that.}
}
\value{
Function f(Mw) of a numeric vector Mw, which by default returns the
rate of events with magnitude > Mw. It has a number of optional arguments.
\cr
If the optional argument 'bounds=TRUE' is passed,
then the function returns upper/lower/median rates of the logic tree as well
as the probability weighted mean rate. \cr
If the optional argument \code{return_all_logic_tree_branches=TRUE} is
passed, then the function returns a list containing a data.frame with all
combinations of parameters, a vector with the Gutenberg-Richter 'a' parameters
(that are derived from the latter in the current function), a vector with the respective
probabilities(weights), a vector with the Mw sequence at which the function
is tabulated, and a matrix with the tabulated values for every branch of the
logic tree. The latter option can be used to scrutinize the results from each
branch of the logic tree. \cr
If the optional argument \code{quantiles} = a vector of probabilities is
passed, then the function evaluates the rate function at each given inverse_quantile
of the logic tree (e.g. quantiles = c(0.1, 0.5, 0.9) would return the lower
10\%, median, and upper 90\% credible interval rates from the logic tree at each Mw) \cr
If the optional argument \code{return_random_curve=TRUE} is passed, then the
function will randomly pick a parameter combination from the logic tree (with
probability equal to the probability of each branch), and evaluate the
exceedance rate of Mw for that parameter combination. This can be useful for
some monte-carlo computations. \cr
If the optional argument \code{epistemic_nonzero_weight=TRUE} is passed, then
return the logic-tree weight assigned to non-zero Mw exceedance rates. This
gives the 'weight with which we think the given magnitude is possible', and
is a useful descriptor of epistemic uncertainties. \cr
ONLY ONE OF THE ABOVE OPTIONAL ARGUMENTS CAN BE PASSED AT A TIME.
If the optional argument \code{account_for_mw_obs_error=TRUE} is passed, then
do the above computations using the posterior weights that account for Mw observation
error. This may be combined with any other optional argument. By default we
use the posterior weights that ignore Mw observation error, irrespective
of whether the empirical CDF of the mw errors was provided.
}
\description{
Create a function f(Mw) which returns the rate of events with 
magnitude >= Mw. Here Mw is a vector of earthquake magnitudes. \cr
The user provides parameters for a variant of the Gutenberg Richter
model, although the parameter 'a' is adjusted to match the long-term
seismogenic slip rate (m/year). Details are explained below. \cr
To account for uncertainties in the GR model parameters, the user may specify
each as a vector of one-or-more parameters with associated probabilities
(which must sum to 1, of course). The code then treats all combinations of
those parameters as having probability equal to the product of the individual
parameter probabilities. It then integrates over the chosen Gutenberg Richter
models to produce a single exceedance rate function, which is returned. \cr
The output rate function also supports a number of optional arguments, which
provide various details on the rate function on each branch of the logic
tree. See details below \cr
}
\note{
The 'a' parameter in the GR model is constrained to match the long-term
seismogenic slip rate.  Given particular values of all the parameters except
a, and a long-term seisomogenic slip rate (= long_term_slip_rate *
coupling_coefficient), the long-term moment rate should equal the rate
integrated from the individual events. Mathematically: \cr
\cr
(definitions) \cr
\eqn{ \mu } = Shear modulus
\cr
S = long term semsmogenic slip rate 
\cr
A = source-zone area 
\cr
\eqn{ s_{i} }= slip for event i 
\cr
\eqn{ a_{i} } = area for event i
\cr
\eqn{rMw_{i} } = rate of events with the same magnitude Mw as event i
\cr
\eqn{ Pr(event_{i} | event with size Mw_{i}) } = the conditional probability
of each event with the same Mw in the event table [i.e. if we take all events
with a given Mw from the table, their conditional probabilities should sum to
1]. 
\cr
(main equation) \cr
\deqn{ \mu  S  A = 
\sum_{i \in events} ( \mu s_{i} a_{i} Pr(event_{i} | event with size Mw_{i}) rMw_{i}) }\cr
\cr
The form of the GR relation implies that a factor of 10^(a) will appear in
the RHS term \eqn{rMw_{i}}, and nowhere else. Hence to
compute 'a', we just compute the LHS and RHS of the above equations,
tentatively assuming a=0 in the latter case, and then it follows that a =
log10(LHS/RHS). \cr
The code also optionally allows us to account for the fraction of seismic
moment released by earthquakes with magnitude smaller than Mw_min. This
reduces the LHS term in the equation above.
}
