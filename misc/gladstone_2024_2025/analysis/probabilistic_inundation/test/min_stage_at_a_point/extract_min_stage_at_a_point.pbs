#!/bin/bash
#PBS -P w85
#PBS -q normalsr
#PBS -l walltime=00:20:00
#PBS -lmem=500GB
#PBS -lncpus=104
#PBS -ljobfs=2GB
#PBS -l wd
#PBS -l storage=scratch/w85+gdata/w85+gdata/fj6

# With 50 scenarios in the Gladstone model (tidal_check):
# Allow 7.5GB per input location. Here that's 5 locations, so 37.5GB.
# Allow 10% leeway so 41GB
# That will need at least 11 CPUs.

# Based on this, with 313 scenarios in the PTHA run:
# Allow 46.95GB per input location. Here that's 6 locations, so 281.7GB.
# Allow 10% leeway so 310GB
# So get a sapphire rapid node.

source ../../../../modules_R_431.sh
module load nci-parallel/1.0.0a

# line count of locations.in.sh
n_tasks=$(wc -l < locations.in.sh)

mpirun -np $n_tasks \
    nci-parallel --input-file locations.in.sh \
    --timeout 4000 \
    --output-dir log

# Previously did in sequence
# for each line in locations.in, extract the max stage at that point
# while read lon lat comment; do
#     Rscript extract_max_stage_at_a_point.R $lon $lat;
# done <locations.in
